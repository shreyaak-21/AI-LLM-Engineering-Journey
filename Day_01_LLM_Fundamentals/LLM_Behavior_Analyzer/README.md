# ğŸ§  LLM Behavior Analyzer & Interactive Chat Playground

A **research-oriented, configurable LLM experimentation platform** built with **Streamlit** and **Ollama (Mistral)** that allows users to analyze and understand Large Language Model (LLM) behavior in real time.

This project is designed **not as a toy chatbot**, but as a **foundation-level industry project** that demonstrates practical understanding of LLM internals, limitations, and controllable parameters.

---

## ğŸš€ Project Motivation

Modern LLM applications require more than just calling an API. Engineers must understand:

* How prompts influence behavior
* Why outputs vary with temperature
* What happens when context windows overflow
* How to handle structured outputs like JSON safely

This project was built to **experiment, analyze, and explain LLM behavior scientifically**.

---

## âœ¨ Key Features

### ğŸ”¹ Interactive Chat Interface

* Streamlit-based UI
* Continuous conversation loop
* Session-based memory

### ğŸ”¹ Prompt Engineering Playground

* Separate **System Prompt** and **User Prompt** inputs
* Dynamic prompt construction
* Role-based prompting

### ğŸ”¹ Generation Controls

* Temperature slider (determinism vs creativity)
* Response format selector:

  * Paragraph
  * Bullet Points
  * JSON

### ğŸ”¹ Context Window & Token Analysis

* Token counting before inference
* Context limit warnings
* Displays token usage clearly

### ğŸ”¹ Manual Chunking Strategy

* Automatically splits long inputs when context limit is exceeded
* Sequential chunk processing
* Aggregates responses safely

### ğŸ”¹ Structured Output Validation (Advanced)

* JSON extraction from messy LLM outputs
* JSON validation
* LLM-powered auto-repair for broken JSON
* Fail-safe fallback mechanism

### ğŸ”¹ Behavior Comparison Mode

* Same prompt tested at different temperatures
* Side-by-side response comparison

### ğŸ”¹ Experiment Tracking

* Logs each experiment with:

  * Prompt
  * Temperature
  * Response format
  * Token usage
  * Model used
* Stored in `experiments.jsonl`

---

## ğŸ—ï¸ High-Level Architecture

```
User Input (Streamlit UI)
        â†“
Prompt Builder
(System + User + Context)
        â†“
LLM Inference Engine
(Ollama â€“ Mistral)
        â†“
Response Post-Processing
(JSON validation / chunking)
        â†“
Experiment Logger
        â†“
UI Output
```

---


## ğŸ§ª What This Project Demonstrates

| Concept               | How Itâ€™s Covered                   |
| --------------------- | ---------------------------------- |
| LLM inference         | Ollama-based local model calls     |
| Prompt engineering    | System vs User prompt separation   |
| Temperature control   | Adjustable creativity slider       |
| Context window limits | Token counting & overflow handling |
| Chunking              | Manual chunking & aggregation      |
| Structured outputs    | JSON enforcement & auto-repair     |
| Experimentation       | Prompt + parameter logging         |

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Prerequisites

* Python 3.9+
* Ollama installed

### 2ï¸âƒ£ Start Ollama

```bash
ollama serve
```

### 3ï¸âƒ£ Pull Mistral Model

```bash
ollama pull mistral
```

### 4ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 5ï¸âƒ£ Run Streamlit App

```bash
streamlit run app.py
```

Open browser at:

```
http://localhost:8501
```

---

## ğŸ§  Example Use Cases

* Analyze how temperature affects determinism
* Test system prompt sensitivity
* Safely generate JSON for downstream pipelines
* Understand LLM context limitations
* Demonstrate LLM behavior in interviews or demos

---



## ğŸ”® Future Enhancements

* Prompt version comparison dashboard
* Schema-based JSON validation
* Model switching (OpenAI / Claude)
* Deployment on Streamlit Cloud

---

## ğŸ Conclusion

This project demonstrates **practical, production-aware understanding of LLM systems** rather than simple chatbot development. It serves as a strong foundation for roles in:

* AI Engineering
* LLM / GenAI Development
* Applied Machine Learning

---

â­ If you found this project useful, feel free to explore and extend it!
